{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kMIn9BpKzldf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6vclmef4mAN",
        "outputId": "63775457-bbda-4f05-afab-ea21fde1a13e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\n",
        "    \"John likes soccer. John plays soccer every afternoon after school.\",\n",
        "    \"Mary reads books. Mary reads books in the library every evening.\",\n",
        "    \"The cat chased the cat around the yard until the cat tired.\",\n",
        "    \"He likes football and she likes football more than any other sport.\"\n",
        "]\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words = word_tokenize(text)\n",
        "    return [word for word in words if word.lower() not in stop_words and word not in string.punctuation]\n",
        "\n",
        "tokenized_doc = [remove_stopwords(t) for t in text]\n",
        "\n",
        "for doc in tokenized_doc:\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpTNRPfm2IFV",
        "outputId": "40cf8b20-6114-4f6d-d16b-bac5e3e6d0bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['John', 'likes', 'soccer', 'John', 'plays', 'soccer', 'every', 'afternoon', 'school']\n",
            "['Mary', 'reads', 'books', 'Mary', 'reads', 'books', 'library', 'every', 'evening']\n",
            "['cat', 'chased', 'cat', 'around', 'yard', 'cat', 'tired']\n",
            "['likes', 'football', 'likes', 'football', 'sport']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate TF\n",
        "from collections import Counter\n",
        "def calculate_tf(doc):\n",
        "  tf_count = Counter(doc)\n",
        "  total_count = len(doc)\n",
        "  return {word: round(count/total_count, 3) for word, count in tf_count.items()}\n",
        "\n",
        "tf_doc = [calculate_tf(doc) for doc in tokenized_doc]\n",
        "\n",
        "for tf in tf_doc:\n",
        "  print(tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTnSLIGQ425s",
        "outputId": "c94e3029-f0c6-4400-ad74-12eefb6af693"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'John': 0.222, 'likes': 0.111, 'soccer': 0.222, 'plays': 0.111, 'every': 0.111, 'afternoon': 0.111, 'school': 0.111}\n",
            "{'Mary': 0.222, 'reads': 0.222, 'books': 0.222, 'library': 0.111, 'every': 0.111, 'evening': 0.111}\n",
            "{'cat': 0.429, 'chased': 0.143, 'around': 0.143, 'yard': 0.143, 'tired': 0.143}\n",
            "{'likes': 0.4, 'football': 0.4, 'sport': 0.2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "#calculate IDF\n",
        "def calculate_idf(tokenized_doc):\n",
        "  N = len(tokenized_doc)\n",
        "  all_terms = set(term for doc in tokenized_doc for term in doc)\n",
        "  idf = {}\n",
        "  for term in all_terms:\n",
        "    # count how many documents contain the word\n",
        "    df = sum(1 for doc in tokenized_doc if term in doc)\n",
        "    idf[term] = math.log(N + 1 / (1 + df))\n",
        "  return idf\n",
        "\n",
        "idf_doc = calculate_idf(tokenized_doc)\n",
        "for idf in idf_doc.items():\n",
        "  print(idf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTozUyUY9qSE",
        "outputId": "68d1207f-e6a1-48c2-d63f-8c03d3e18240"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('sport', 1.5040773967762742)\n",
            "('every', 1.466337068793427)\n",
            "('yard', 1.5040773967762742)\n",
            "('soccer', 1.5040773967762742)\n",
            "('evening', 1.5040773967762742)\n",
            "('afternoon', 1.5040773967762742)\n",
            "('tired', 1.5040773967762742)\n",
            "('reads', 1.5040773967762742)\n",
            "('library', 1.5040773967762742)\n",
            "('cat', 1.5040773967762742)\n",
            "('John', 1.5040773967762742)\n",
            "('books', 1.5040773967762742)\n",
            "('Mary', 1.5040773967762742)\n",
            "('likes', 1.466337068793427)\n",
            "('plays', 1.5040773967762742)\n",
            "('school', 1.5040773967762742)\n",
            "('chased', 1.5040773967762742)\n",
            "('around', 1.5040773967762742)\n",
            "('football', 1.5040773967762742)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate TF-IDF\n",
        "\n",
        "def calculate_tf_idf(tf, idf):\n",
        "  tf_idf = {}\n",
        "  for word, tf_value in tf.items():\n",
        "    tf_idf[word] = tf_value * idf[word]\n",
        "  return tf_idf\n",
        "\n",
        "tf_idf_doc = [calculate_tf_idf(tf, idf_doc) for tf in tf_doc]\n",
        "\n",
        "for tf_idf in tf_idf_doc:\n",
        "  print(tf_idf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm0WDdLVQeuM",
        "outputId": "c4409b5f-b816-4e12-b898-d8109376372e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'John': 0.3339051820843329, 'likes': 0.16276341463607039, 'soccer': 0.3339051820843329, 'plays': 0.16695259104216645, 'every': 0.16276341463607039, 'afternoon': 0.16695259104216645, 'school': 0.16695259104216645}\n",
            "{'Mary': 0.3339051820843329, 'reads': 0.3339051820843329, 'books': 0.3339051820843329, 'library': 0.16695259104216645, 'every': 0.16276341463607039, 'evening': 0.16695259104216645}\n",
            "{'cat': 0.6452492032170216, 'chased': 0.21508306773900718, 'around': 0.21508306773900718, 'yard': 0.21508306773900718, 'tired': 0.21508306773900718}\n",
            "{'likes': 0.5865348275173708, 'football': 0.6016309587105098, 'sport': 0.3008154793552549}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(tokenized_doc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yORaN0cxR3zb",
        "outputId": "83842ce6-cffe-40ad-8bb0-ba5bfdd675a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'John': 2,\n",
              "         'likes': 1,\n",
              "         'soccer': 2,\n",
              "         'plays': 1,\n",
              "         'every': 1,\n",
              "         'afternoon': 1,\n",
              "         'school': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    \"I love horror movie.\",\n",
        "    \"Lights out is a horror movie.\"\n",
        "]\n",
        "\n",
        "tokenized_doc = [remove_stopwords(t) for t in docs]\n",
        "for doc in tokenized_doc:\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4J70zOAUMBb",
        "outputId": "b9856d55-163c-4961-8ecb-b7dd7d2c904d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['love', 'horror', 'movie']\n",
            "['Lights', 'horror', 'movie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_terms = set(term for doc in tokenized_doc for term in doc)\n",
        "print(unique_terms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOxjVCrrUg7N",
        "outputId": "a6625188-0ef3-4bc8-bf0d-7903db772bd4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'horror', 'love', 'movie', 'Lights'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vector(doc):\n",
        "       return [1 if term in doc else 0 for term in unique_terms]\n",
        "\n",
        "vectors = [create_vector(doc) for doc in tokenized_doc]\n",
        "\n",
        "for vector in vectors:\n",
        "    print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdHipQQMU8S7",
        "outputId": "6b441b43-77ea-477c-bc41-fc0a0704c31e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 0]\n",
            "[1, 0, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_sim(v1, v2):\n",
        "  dot_product = sum(a * b for a, b in zip(v1, v2))\n",
        "  mag_v1 = math.sqrt(sum(a**2 for a in v1))\n",
        "  mag_v2 = math.sqrt(sum(b**2 for b in v2))\n",
        "  return dot_product / (mag_v1 * mag_v2)\n",
        "\n",
        "similarity = cosine_sim(vectors[0], vectors[1])\n",
        "print(\"Cosine Similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd9f0dodJqqf",
        "outputId": "993d5482-5b7e-4a95-b3c5-b4da659201e2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity: 0.6666666666666667\n"
          ]
        }
      ]
    }
  ]
}