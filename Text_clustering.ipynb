{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "RiG4dNXnulCH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    \"john plays football\",\n",
        "    \"library books read\",\n",
        "    \"mary likes tennis\",\n",
        "    \"books novels library\",\n",
        "    \"john likes football\",\n",
        "    \"mary reads novels\"\n",
        "]"
      ],
      "metadata": {
        "id": "dKhgutm5uz0k"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-means**"
      ],
      "metadata": {
        "id": "F6KC83r-vehf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary and vectorization\n",
        "vocab = list(set(word for doc in docs for word in doc.split()))\n",
        "def vectorize(doc):\n",
        "    return np.array([1 if word in doc.split() else 0 for word in vocab])\n",
        "\n",
        "X = np.array([vectorize(doc) for doc in docs])"
      ],
      "metadata": {
        "id": "YlMFMCqTra96"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "038eQCJgqlzu",
        "outputId": "9429a2b0-8009-4ce2-fc9c-8f8fd8ff4474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1: 'john plays football' -> Cluster 1\n",
            "Document 2: 'library books read' -> Cluster 0\n",
            "Document 3: 'mary likes tennis' -> Cluster 0\n",
            "Document 4: 'books novels library' -> Cluster 0\n",
            "Document 5: 'john likes football' -> Cluster 1\n",
            "Document 6: 'mary reads novels' -> Cluster 0\n"
          ]
        }
      ],
      "source": [
        "# K-Means manually\n",
        "def kmeans(X, k=2, max_iters=100):\n",
        "    centroids = X[np.random.choice(len(X), k, replace=False)]\n",
        "\n",
        "    for _ in range(max_iters):\n",
        "        clusters = [np.argmin([np.sum(np.abs(x - c)) for c in centroids]) for x in X]\n",
        "        new_centroids = []\n",
        "\n",
        "        for i in range(k):\n",
        "            points = X[np.array(clusters) == i]\n",
        "            new_centroids.append(points.mean(axis=0) if len(points) > 0 else centroids[i])\n",
        "\n",
        "        new_centroids = np.array(new_centroids)\n",
        "\n",
        "        if np.allclose(centroids, new_centroids):\n",
        "            break\n",
        "        centroids = new_centroids\n",
        "\n",
        "    return clusters\n",
        "\n",
        "clusters = kmeans(X, k=2)\n",
        "\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"Document {i+1}: '{doc}' -> Cluster {clusters[i]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-medoids**"
      ],
      "metadata": {
        "id": "wnvsgX9iviKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kmedoids(X, k=2, max_iters=100):\n",
        "    medoids = X[np.random.choice(len(X), k, replace=False)]\n",
        "\n",
        "    for _ in range(max_iters):\n",
        "        clusters = [np.argmin([np.sum(np.abs(x - m)) for m in medoids]) for x in X]\n",
        "        new_medoids = []\n",
        "\n",
        "        for i in range(k):\n",
        "            points = X[np.array(clusters) == i]\n",
        "\n",
        "            if len(points) == 0:\n",
        "                new_medoids.append(medoids[i])\n",
        "                continue\n",
        "\n",
        "            medoid = points[np.argmin([sum(np.linalg.norm(p - points, axis=1)) for p in points])]\n",
        "            new_medoids.append(medoid)\n",
        "\n",
        "        new_medoids = np.array(new_medoids)\n",
        "\n",
        "        if np.allclose(medoids, new_medoids):\n",
        "            break\n",
        "        medoids = new_medoids\n",
        "\n",
        "    return clusters\n",
        "\n",
        "kmedoid_clusters = kmedoids(X, k=2)\n",
        "\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"Document {i+1}: '{doc}' -> Cluster {kmedoid_clusters[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAwmzjnLtRmR",
        "outputId": "639c919e-3f73-45dd-d805-b21040d49ccf"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1: 'john plays football' -> Cluster 0\n",
            "Document 2: 'library books read' -> Cluster 1\n",
            "Document 3: 'mary likes tennis' -> Cluster 0\n",
            "Document 4: 'books novels library' -> Cluster 1\n",
            "Document 5: 'john likes football' -> Cluster 0\n",
            "Document 6: 'mary reads novels' -> Cluster 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text shingling**"
      ],
      "metadata": {
        "id": "wprexPCrvlMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    \"machine learning is a field of artificial intelligence that uses statistical techniques to give computer systems the ability to learn from data\",\n",
        "    \"deep learning is a subset of machine learning that uses neural networks with representation learning to model complex patterns in data\",\n",
        "    \"natural language processing enables computers to understand human language and involves text analysis, tokenization, and semantic modeling\",\n",
        "    \"computer vision is a field that enables machines to interpret and process visual information from the world, including images and videos\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "RRbfgzxOySwm"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shingles(doc, k=2):\n",
        "    words = doc.split()\n",
        "    return set([\" \".join(words[i:i+k]) for i in range(len(words)-k+1)])\n",
        "\n",
        "doc_shingles = [shingles(doc, k=2) for doc in docs]\n",
        "\n",
        "# Print shingles for each document\n",
        "for i, s in enumerate(doc_shingles):\n",
        "    print(f\"Document {i+1}: Shingles (count={len(s)})\")\n",
        "    print(sorted(list(s))[:10], \"...\")  # show first 10 shingles for brevity\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NKECCHAyWrH",
        "outputId": "6d8515e2-4ad5-4931-d5db-17108cb12b17"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1: Shingles (count=21)\n",
            "['a field', 'ability to', 'artificial intelligence', 'computer systems', 'field of', 'from data', 'give computer', 'intelligence that', 'is a', 'learn from'] ...\n",
            "Document 2: Shingles (count=20)\n",
            "['a subset', 'complex patterns', 'deep learning', 'in data', 'is a', 'learning is', 'learning that', 'learning to', 'machine learning', 'model complex'] ...\n",
            "Document 3: Shingles (count=16)\n",
            "['analysis, tokenization,', 'and involves', 'and semantic', 'computers to', 'enables computers', 'human language', 'involves text', 'language and', 'language processing', 'natural language'] ...\n",
            "Document 4: Shingles (count=20)\n",
            "['a field', 'and process', 'and videos', 'computer vision', 'enables machines', 'field that', 'from the', 'images and', 'including images', 'information from'] ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard(s1, s2):\n",
        "    return len(s1 & s2) / len(s1 | s2)\n",
        "\n",
        "n = len(docs)\n",
        "jac_matrix = np.zeros((n,n))\n",
        "for i in range(n):\n",
        "    for j in range(n):\n",
        "        jac_matrix[i,j] = jaccard(doc_shingles[i], doc_shingles[j])\n",
        "\n",
        "# Print numeric matrix\n",
        "print(\"Jaccard Similarity Matrix:\")\n",
        "for i in range(n):\n",
        "    print([round(float(val), 2) for val in jac_matrix[i]])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQps1HeGvk_J",
        "outputId": "ff4c2610-8ba4-44f4-e33e-8c585f093f2c"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard Similarity Matrix:\n",
            "[1.0, 0.11, 0.0, 0.05]\n",
            "[0.11, 1.0, 0.0, 0.03]\n",
            "[0.0, 0.0, 1.0, 0.0]\n",
            "[0.05, 0.03, 0.0, 1.0]\n"
          ]
        }
      ]
    }
  ]
}