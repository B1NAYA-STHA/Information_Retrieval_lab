{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter, defaultdict\n",
        "import math\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "2ChWklAFlUHA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training dataset\n",
        "docs = [\n",
        "    [\"john\", \"plays\", \"football\"],\n",
        "    [\"library\", \"books\", \"read\"],\n",
        "    [\"mary\", \"likes\", \"tennis\"],\n",
        "    [\"books\", \"novels\", \"library\"]\n",
        "]\n",
        "labels = [\"Sports\", \"Library\", \"Sports\", \"Library\"]"
      ],
      "metadata": {
        "id": "wRiw4M_NldaW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes**"
      ],
      "metadata": {
        "id": "V4oNMuTBm8zn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n7hIA6lvkSvx"
      },
      "outputs": [],
      "source": [
        "# Calculate priors and likelihoods\n",
        "class_docs = defaultdict(list)\n",
        "for doc, label in zip(docs, labels):\n",
        "    class_docs[label].extend(doc)\n",
        "\n",
        "# Priors\n",
        "priors = {c: len([1 for l in labels if l==c]) / len(labels) for c in set(labels)}\n",
        "\n",
        "# Likelihoods with Laplace smoothing\n",
        "likelihoods = {}\n",
        "vocab = set(word for doc in docs for word in doc)\n",
        "for c, words in class_docs.items():\n",
        "    word_counts = Counter(words)\n",
        "    total_words = len(words)\n",
        "    likelihoods[c] = {w: (word_counts[w] + 1) / (total_words + len(vocab)) for w in vocab}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Predict\n",
        "def predict_nb(doc):\n",
        "    scores = {}\n",
        "    for c in priors:\n",
        "        scores[c] = math.log(priors[c])\n",
        "        for w in doc:\n",
        "            if w in vocab:\n",
        "                scores[c] += math.log(likelihoods[c][w])\n",
        "    return max(scores, key=scores.get)\n",
        "\n",
        "print(\"Doc: ['football', 'match'] ->\", predict_nb([\"football\", \"match\"]))\n",
        "print(\"Doc: ['read', 'books'] ->\", predict_nb([\"read\", \"books\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-cFxdNFmIip",
        "outputId": "aff7177d-86b5-45f5-e7d5-f715689dbf5b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doc: ['football', 'match'] -> Sports\n",
            "Doc: ['read', 'books'] -> Library\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree**"
      ],
      "metadata": {
        "id": "9wcREIiwnBnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decision_tree_predict(doc):\n",
        "    if \"football\" in doc or \"tennis\" in doc:\n",
        "        return \"Sports\"\n",
        "    elif \"books\" in doc or \"library\" in doc:\n",
        "        return \"Library\"\n",
        "    else:\n",
        "        return \"Unknown\"\n",
        "\n",
        "print(\"Doc: ['football', 'game'] ->\", decision_tree_predict([\"football\", \"game\"]))\n",
        "print(\"Doc: ['books', 'library'] ->\", decision_tree_predict([\"books\", \"library\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uviHFXHDm8CW",
        "outputId": "67727223-7692-4cc2-d859-d7bca91e378e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doc: ['football', 'game'] -> Sports\n",
            "Doc: ['books', 'library'] -> Library\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN**"
      ],
      "metadata": {
        "id": "Ab_tfGnPnk14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocabulary\n",
        "vocab = list(set(word for doc in docs for word in doc))\n",
        "word_index = {w:i for i,w in enumerate(vocab)}\n",
        "\n",
        "# Vectorize docs\n",
        "def vectorize(doc):\n",
        "    vec = [0]*len(vocab)\n",
        "    for w in doc:\n",
        "        if w in word_index:\n",
        "            vec[word_index[w]] += 1\n",
        "    return np.array(vec)\n",
        "\n",
        "X = [vectorize(doc) for doc in docs]\n",
        "\n",
        "def cosine_sim(v1, v2):\n",
        "    return np.dot(v1, v2) / (np.linalg.norm(v1)*np.linalg.norm(v2) + 1e-6)"
      ],
      "metadata": {
        "id": "V5k9hdzAn5jx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_predict(query, k=3):\n",
        "    q_vec = vectorize(query)\n",
        "    sims = [(cosine_sim(q_vec, x), label) for x,label in zip(X, labels)]\n",
        "    sims.sort(reverse=True)\n",
        "    top_k = [label for _,label in sims[:k]]\n",
        "    return Counter(top_k).most_common(1)[0][0]\n",
        "\n",
        "print(\"Doc: ['tennis', 'game'] ->\", knn_predict([\"tennis\", \"game\"]))\n",
        "print(\"Doc: ['novels', 'library'] ->\", knn_predict([\"novels\", \"library\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mAdCD-inkgZ",
        "outputId": "423f9ecf-ee4d-4fce-a599-6e26d4d1b231"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doc: ['tennis', 'game'] -> Sports\n",
            "Doc: ['novels', 'library'] -> Library\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rocchio**"
      ],
      "metadata": {
        "id": "leWK-DjjoSxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = [\"football\", \"match\"]\n",
        "\n",
        "# Relevant docs: doc[0], doc[2]\n",
        "relevant_ids = [0, 2]\n",
        "# Non-relevant docs: doc[1], doc[3]\n",
        "non_relevant_ids = [1, 3]\n",
        "\n",
        "#Build Vocabulary\n",
        "vocab = sorted(set(w for d in docs for w in d) | set(query))\n",
        "idx = {w:i for i,w in enumerate(vocab)}\n",
        "\n",
        "print(\"Vocab:\", vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1bHnzPZqKEv",
        "outputId": "703044a9-7307-4401-9b20-027387801e38"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab: ['books', 'football', 'john', 'library', 'likes', 'mary', 'match', 'novels', 'plays', 'read', 'tennis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize\n",
        "def vectorize(words):\n",
        "    vec = np.zeros(len(vocab))\n",
        "    counts = Counter(words)\n",
        "    for w, c in counts.items():\n",
        "        vec[idx[w]] = c\n",
        "    return vec\n",
        "\n",
        "X = [vectorize(doc) for doc in docs]\n",
        "Q = vectorize(query)"
      ],
      "metadata": {
        "id": "F1VstcDBqQh4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rocchio Parameters\n",
        "alpha, beta, gamma = 1.0, 0.75, 0.15\n",
        "\n",
        "# Compute centroids\n",
        "relevant_vec = np.mean([X[i] for i in relevant_ids], axis=0)\n",
        "non_relevant_vec = np.mean([X[i] for i in non_relevant_ids], axis=0)\n",
        "\n",
        "# New query vector\n",
        "Q_new = alpha * Q + beta * relevant_vec - gamma * non_relevant_vec\n",
        "\n",
        "# Show Top Terms\n",
        "top_idx = Q_new.argsort()[::-1][:5]\n",
        "expanded_terms = [vocab[i] for i in top_idx]\n",
        "\n",
        "print(\"\\nOriginal Query:\", query)\n",
        "print(\"Original Vector:\", Q)\n",
        "print(\"New Query Vector:\", np.round(Q_new, 2))\n",
        "print(\"Expanded Query Terms:\", expanded_terms)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB1NdaBRpjaP",
        "outputId": "31d0889d-ab2a-4670-d3ca-de9ca6deeab5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original Query: ['football', 'match']\n",
            "Original Vector: [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "New Query Vector: [-0.15  1.38  0.38 -0.15  0.38  0.38  1.   -0.08  0.38 -0.08  0.38]\n",
            "Expanded Query Terms: ['football', 'match', 'tennis', 'john', 'plays']\n"
          ]
        }
      ]
    }
  ]
}