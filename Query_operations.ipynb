{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "from collections import Counter\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, words\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.metrics import edit_distance\n",
        "nltk.download('wordnet')\n",
        "nltk.download(\"words\")\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_0U7EqIpsBU",
        "outputId": "519e1dc9-f859-48d9-d546-c81483fe42b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simple Thesaurus based**"
      ],
      "metadata": {
        "id": "qpw5pNyQp-np"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjFhnD9Ho7pa"
      },
      "outputs": [],
      "source": [
        "def expand_query_with_synonyms(query):\n",
        "    query_tokens = query.lower().split()\n",
        "    expansion = set(query_tokens)\n",
        "\n",
        "    for term in query_tokens:\n",
        "        for syn in wordnet.synsets(term):\n",
        "            for lemma in syn.lemmas():\n",
        "                expansion.add(lemma.name().replace('_', ' '))\n",
        "    return list(expansion)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"car\"\n",
        "expanded_query = expand_query_with_synonyms(query)\n",
        "print(\"Original Query:\", query)\n",
        "print(\"Expanded Query:\", expanded_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1Eciq9UqZPd",
        "outputId": "9f061911-67bc-47c2-de85-3966c165e463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Query: car\n",
            "Expanded Query: ['motorcar', 'railway car', 'automobile', 'elevator car', 'cable car', 'machine', 'railroad car', 'railcar', 'car', 'gondola', 'auto']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pseudo Relevance based expansion**"
      ],
      "metadata": {
        "id": "P8AWKAgcqobj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\n",
        "    \"John likes soccer. John plays soccer every afternoon after school.\",\n",
        "    \"Mary reads books. Mary reads books in the library every evening.\",\n",
        "    \"The cat chased the cat around the yard until the cat tired.\",\n",
        "    \"He likes football and she likes football more than any other sport.\",\n",
        "    \"Soccer is a popular sport around the world. Many people play soccer.\",\n",
        "    \"Books and reading help Mary improve her knowledge and vocabulary.\",\n",
        "    \"Cats are playful and sometimes chase each other in the yard.\"\n",
        "]\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words = word_tokenize(text)\n",
        "    return [word for word in words if word.lower() not in stop_words and word not in string.punctuation]\n",
        "\n",
        "tokenized_doc = [remove_stopwords(t) for t in text]\n",
        "\n",
        "tokenized_doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3pakxdGqEBO",
        "outputId": "71adf087-03f4-4ed9-b454-a9895427ccb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['John',\n",
              "  'likes',\n",
              "  'soccer',\n",
              "  'John',\n",
              "  'plays',\n",
              "  'soccer',\n",
              "  'every',\n",
              "  'afternoon',\n",
              "  'school'],\n",
              " ['Mary',\n",
              "  'reads',\n",
              "  'books',\n",
              "  'Mary',\n",
              "  'reads',\n",
              "  'books',\n",
              "  'library',\n",
              "  'every',\n",
              "  'evening'],\n",
              " ['cat', 'chased', 'cat', 'around', 'yard', 'cat', 'tired'],\n",
              " ['likes', 'football', 'likes', 'football', 'sport'],\n",
              " ['Soccer',\n",
              "  'popular',\n",
              "  'sport',\n",
              "  'around',\n",
              "  'world',\n",
              "  'Many',\n",
              "  'people',\n",
              "  'play',\n",
              "  'soccer'],\n",
              " ['Books', 'reading', 'help', 'Mary', 'improve', 'knowledge', 'vocabulary'],\n",
              " ['Cats', 'playful', 'sometimes', 'chase', 'yard']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In real IR, we would rank docs. But,here we simulate by matching query terms.\n",
        "def retrieve_top_docs(query_tokens, tokenized_docs, top_k=3):\n",
        "    scores = []\n",
        "    for i, doc in enumerate(tokenized_docs):\n",
        "        score = sum(doc.count(term) for term in query_tokens)  # simple frequency score\n",
        "        scores.append((i, score))\n",
        "    # Sort by score descending\n",
        "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
        "    top_docs = [tokenized_docs[i] for i, s in scores[:top_k] if s > 0]\n",
        "    return top_docs"
      ],
      "metadata": {
        "id": "LD9Q4ZMyr6Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pseudo_relevance_expansion(query_tokens, top_docs_tokens, top_n=5):\n",
        "    counter = Counter()\n",
        "    for doc in top_docs_tokens:\n",
        "        counter.update(doc)\n",
        "\n",
        "    # Remove original query terms\n",
        "    for term in query_tokens:\n",
        "        if term in counter:\n",
        "            del counter[term]\n",
        "\n",
        "    # Select top-n frequent terms\n",
        "    expansion_terms = [t for t, _ in counter.most_common(top_n)]\n",
        "    return query_tokens + expansion_terms"
      ],
      "metadata": {
        "id": "0XOGdDQvseax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_tokens = [\"soccer\", \"sport\"]\n",
        "top_docs = retrieve_top_docs(query_tokens, tokenized_doc, top_k=3)\n",
        "\n",
        "expanded_query = pseudo_relevance_expansion(query_tokens, top_docs, top_n=5)"
      ],
      "metadata": {
        "id": "rW1gvqS4sFh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Query:\", query_tokens)\n",
        "print(\"Top-K Retrieved Docs (Tokens):\")\n",
        "for i, doc in enumerate(top_docs):\n",
        "    print(f\"Doc {i+1}:\", doc)\n",
        "print(\"Expanded Query:\", expanded_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOSrCKbrsqIY",
        "outputId": "e51a2257-4731-405e-ffca-1cea33cc6454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Query: ['soccer', 'sport']\n",
            "Top-K Retrieved Docs (Tokens):\n",
            "Doc 1: ['John', 'likes', 'soccer', 'John', 'plays', 'soccer', 'every', 'afternoon', 'school']\n",
            "Doc 2: ['Soccer', 'popular', 'sport', 'around', 'world', 'Many', 'people', 'play', 'soccer']\n",
            "Doc 3: ['likes', 'football', 'likes', 'football', 'sport']\n",
            "Expanded Query: ['soccer', 'sport', 'likes', 'John', 'football', 'plays', 'every']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spelling correction(Edit distance)**"
      ],
      "metadata": {
        "id": "hp1fK7t5tQeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = set(words.words())\n",
        "\n",
        "def correct_spelling(query):\n",
        "    corrected = []\n",
        "    for term in query.split():\n",
        "        if term in word_list:\n",
        "            corrected.append(term)\n",
        "        else:\n",
        "            # find closest word by edit distance\n",
        "            closest_word = min(word_list, key=lambda w: edit_distance(term, w))\n",
        "            corrected.append(closest_word)\n",
        "    return \" \".join(corrected)"
      ],
      "metadata": {
        "id": "gNTGMfchtWpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"socer plaing in fied\"\n",
        "corrected_query = correct_spelling(query)\n",
        "\n",
        "print(\"Original Query:\", query)\n",
        "print(\"Corrected Query:\", corrected_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HflmjqvbtqCt",
        "outputId": "37ffcde1-642e-418a-d74e-a09487a94098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Query: socer plaing in fied\n",
            "Corrected Query: socker plating in field\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-gram indexes**"
      ],
      "metadata": {
        "id": "yrLiCNXEvhhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Vocabulary\n",
        "vocab = [\"soccer\", \"football\", \"tennis\", \"library\", \"playing\", \"john\", \"mary\"]\n",
        "\n",
        "# Build Simple K-Gram Index\n",
        "def build_kgram_index(vocab, k=2):\n",
        "    kgram_index = defaultdict(set)\n",
        "    for word in vocab:\n",
        "        word_padded = f\"${word}$\"  # add start/end markers\n",
        "        for i in range(len(word_padded)-k+1):\n",
        "            kgram = word_padded[i:i+k]\n",
        "            kgram_index[kgram].add(word)\n",
        "    return kgram_index\n",
        "\n",
        "kgram_index = build_kgram_index(vocab, k=2)\n"
      ],
      "metadata": {
        "id": "ZFgdPWCfvJUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display K-Gram Index\n",
        "for kgram, words in kgram_index.items():\n",
        "    print(f\"{kgram}: {words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRdTg9RgvV3A",
        "outputId": "014b152e-a01c-4cf2-8806-ab1d8a381da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$s: {'soccer'}\n",
            "so: {'soccer'}\n",
            "oc: {'soccer'}\n",
            "cc: {'soccer'}\n",
            "ce: {'soccer'}\n",
            "er: {'soccer'}\n",
            "r$: {'soccer'}\n",
            "$f: {'football'}\n",
            "fo: {'football'}\n",
            "oo: {'football'}\n",
            "ot: {'football'}\n",
            "tb: {'football'}\n",
            "ba: {'football'}\n",
            "al: {'football'}\n",
            "ll: {'football'}\n",
            "l$: {'football'}\n",
            "$t: {'tennis'}\n",
            "te: {'tennis'}\n",
            "en: {'tennis'}\n",
            "nn: {'tennis'}\n",
            "ni: {'tennis'}\n",
            "is: {'tennis'}\n",
            "s$: {'tennis'}\n",
            "$l: {'library'}\n",
            "li: {'library'}\n",
            "ib: {'library'}\n",
            "br: {'library'}\n",
            "ra: {'library'}\n",
            "ar: {'mary', 'library'}\n",
            "ry: {'mary', 'library'}\n",
            "y$: {'mary', 'library'}\n",
            "$p: {'playing'}\n",
            "pl: {'playing'}\n",
            "la: {'playing'}\n",
            "ay: {'playing'}\n",
            "yi: {'playing'}\n",
            "in: {'playing'}\n",
            "ng: {'playing'}\n",
            "g$: {'playing'}\n",
            "$j: {'john'}\n",
            "jo: {'john'}\n",
            "oh: {'john'}\n",
            "hn: {'john'}\n",
            "n$: {'john'}\n",
            "$m: {'mary'}\n",
            "ma: {'mary'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Candidate Search\n",
        "def get_candidates(word, kgram_index, k=2):\n",
        "    word_padded = f\"${word}$\"\n",
        "    word_kgrams = [word_padded[i:i+k] for i in range(len(word_padded)-k+1)]\n",
        "\n",
        "    candidates = set()\n",
        "    for kg in word_kgrams:\n",
        "        if kg in kgram_index:\n",
        "            candidates.update(kgram_index[kg])\n",
        "    return candidates"
      ],
      "metadata": {
        "id": "iqxBvXQsveCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "misspelled = \"socer\"\n",
        "candidates = get_candidates(misspelled, kgram_index)\n",
        "print(\"\\nMisspelled word:\", misspelled)\n",
        "print(\"Candidate corrections:\", candidates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fM9b-86vfsC",
        "outputId": "751077bd-2300-4236-acc1-1f0e79cae117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Misspelled word: socer\n",
            "Candidate corrections: {'soccer'}\n"
          ]
        }
      ]
    }
  ]
}