{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9J57OjIVgv4C"
      },
      "outputs": [],
      "source": [
        "def evaluate_ir(relevant, retrieved):\n",
        "    relevant = set(relevant)\n",
        "    retrieved = set(retrieved)\n",
        "\n",
        "    relevant_retrieved = relevant & retrieved\n",
        "\n",
        "    precision = len(relevant_retrieved) / len(retrieved) if retrieved else 0\n",
        "    recall = len(relevant_retrieved) / len(relevant) if relevant else 0\n",
        "    f1 = (2 * precision * recall) / (precision + recall) if (precision+recall) > 0 else 0\n",
        "\n",
        "    return precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_docs = {2, 4, 7, 9}      # ground truth\n",
        "retrieved_docs = {1, 2, 4, 6, 7}  # system output\n",
        "\n",
        "precision, recall, f1 = evaluate_ir(relevant_docs, retrieved_docs)\n",
        "\n",
        "print(\"Precision:\", round(precision, 3))\n",
        "print(\"Recall:\", round(recall, 3))\n",
        "print(\"F1-Score:\", round(f1, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G14jDdpBoP9i",
        "outputId": "9d7ddd3c-dc12-4bbd-a02d-cb1012da4cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.6\n",
            "Recall: 0.75\n",
            "F1-Score: 0.667\n"
          ]
        }
      ]
    }
  ]
}